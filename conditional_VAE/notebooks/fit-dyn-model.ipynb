{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a631f4",
   "metadata": {},
   "source": [
    "# Fit a dynamical model to sc-flow data\n",
    "\n",
    "In this notebook, we will\n",
    "\n",
    "1. Import and visualize simulated single cell flow cytometry data\n",
    "2. Develop a conditional variational autoencoder that finds a latent space representation, and estimates differentiation rates\n",
    "3. Visualize the results and compare the inferred values with the ground truth\n",
    "4. Restrict the model space and improve our estimates\n",
    "\n",
    "We start by importing some python modules. We will use `torch` and `pyro` for deep learing and variational inference. This is faster on a GPU, but can also be done on a CPU if required. We therefore check if a GPU is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for importing the dataset\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from sklearn.decomposition import PCA # for dimensionality reduction\n",
    "import numpy as np # for numerical computations\n",
    "import tqdm # for progress bars\n",
    "import torch # PyTorch for tensor computations\n",
    "import pyro # probabilistic programming library\n",
    "# import objects for stochastic variational inference\n",
    "from pyro.infer import SVI, Trace_ELBO, JitTrace_ELBO \n",
    "from pyro.optim import Adam\n",
    "\n",
    "\n",
    "# allow imports from parent directory (for scdynsys package)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# import the dynamical VAE model\n",
    "from scdynsys.dynamic_vae import VAEgmmdyn\n",
    "from scdynsys.utilities import cell_type_colors\n",
    "\n",
    "# check if CUDA (GPU) is available and set device accordingly\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "print(\"CUDA available:\", USE_CUDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fb3b3",
   "metadata": {},
   "source": [
    "## 1. Import the data and visualize\n",
    "\n",
    "The dataset contains values for 12 flow cytometry markers, and time and celltype information for each cell. The celltype is typically not known, but as this data is simulated, we actually know the celltype. Of course, we should not use this information in our model fitting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b92672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the (simulated) dataset\n",
    "dataset = pd.read_csv('../data/simulated_time_series_data.csv')\n",
    "\n",
    "# look at the first few rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274dbbd",
   "metadata": {},
   "source": [
    "### Inspection of the data\n",
    "\n",
    "The dataset contains: \n",
    "\n",
    "- 12 flow cytometry markers \n",
    "- sampling time information\n",
    "\n",
    "Let's plot 1-d flow plots (marginal densities) \n",
    "and see how these change with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6483711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot marginal densities of markers at different time points\n",
    "time_points = sorted(dataset['Timepoint'].unique())\n",
    "num_timepoints = len(time_points)\n",
    "\n",
    "# marker names:\n",
    "markers = [col for col in dataset.columns if col not in ['Timepoint', 'CellType']]\n",
    "num_markers = len(markers)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    num_timepoints, num_markers,\n",
    "    figsize=(2*num_markers, 2*num_timepoints), \n",
    "    sharex='col', sharey=True\n",
    ")\n",
    "\n",
    "# remove space between subplots\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "\n",
    "\n",
    "# spit data by marker and time point and plot histograms (1D FACS plots)\n",
    "for j, marker in enumerate(markers):\n",
    "    for i, tp in enumerate(time_points):\n",
    "        data_tp = dataset[dataset['Timepoint'] == tp][marker]\n",
    "        ax = axs[i,j]\n",
    "        ax.hist(data_tp, bins=30, density=True, color='k', alpha=0.7)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f'Time {tp}')\n",
    "        if i == 0:\n",
    "            ax.set_title(marker)\n",
    "        ax.set(xticks=[], yticks=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e476199",
   "metadata": {},
   "source": [
    "The dataset is quite large, and so we'll subsample to speed up\n",
    "computations. \n",
    "Next, we'll define some arrays and tensors that are required below.\n",
    "\n",
    "These are some of the key elements:\n",
    "\n",
    "* `xs`: these are the (scaled) marker expression measured by flow cytometry.\n",
    "* `ts`: time point for each cell.\n",
    "* `celltypes`: the ground-truth cell type for each cell (only known because we simulate the data)\n",
    "* `utime`: these are the unique time points in the data set. The reason for using these instead of `ts` is that we only have to evaluate our dynamical model at these time points. If we would evaluate at `ts` we would be doing A LOT of redundant work.\n",
    "\n",
    "Torch and Pyro work with so-called \"tensors\" instead of e.g. numpy arrays. So we will conver the \"raw\" arrays to \"tensor\". We also move the data to the specified devide (the CPU or the GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d82b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample the dataset for faster experimentation\n",
    "\n",
    "dataset = dataset.sample(20000, random_state=42)\n",
    "\n",
    "# prepare tensors for model fitting: xs and ts (marker expression and time)\n",
    "\n",
    "xs_raw = dataset.iloc[:, 0:-1].values\n",
    "ts_raw = dataset[\"Timepoint\"].values\n",
    "celltypes = dataset[\"CellType\"].values\n",
    "celltypes_unique = np.unique(celltypes)\n",
    "print(f\"Unique cell types: {celltypes_unique}\")\n",
    "\n",
    "# torch and Pyro work with tensors: these are arrays with additional functionality\n",
    "# to support GPU computations and automatic differentiation\n",
    "\n",
    "xs_tensor = torch.tensor(xs_raw, dtype=torch.float32, device=DEVICE)\n",
    "ts_tensor = torch.tensor(ts_raw, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "# we need to know the data dimension and number of samples\n",
    "\n",
    "data_dim = xs_tensor.shape[1]  # number of features\n",
    "n_samples = xs_tensor.shape[0]\n",
    "\n",
    "print(f\"Number of feature5: {data_dim}, Number of samples: {n_samples}\")\n",
    "\n",
    "# create unique time tensor\n",
    "\n",
    "utime_raw = np.sort(dataset[\"Timepoint\"].unique())\n",
    "utime_tensor = torch.tensor(utime_raw, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "num_timepoints = len(utime_raw)\n",
    "print(f\"Number of unique time points: {num_timepoints}\")\n",
    "\n",
    "print(f\"Unique time points: {utime_raw}\")\n",
    "\n",
    "# create time index tensor\n",
    "\n",
    "xtime_raw = np.sum([i * (ts_raw == t) for i, t in enumerate(utime_raw)], axis=0)\n",
    "xtime_tensor = torch.tensor(xtime_raw, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# check that the time index tensor is correct\n",
    "\n",
    "assert torch.all(utime_tensor[xtime_tensor] == ts_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5301e",
   "metadata": {},
   "source": [
    "## 2. Develop a conditional VAE\n",
    "\n",
    "Using Pyro for building VAE models is relatively easy, as we don't have to manually calculate the ELBO, or worry about [\"reparameterization tricks\"](https://en.wikipedia.org/wiki/Reparameterization_trick).\n",
    "\n",
    "However, Pyro has a couple of quirks, leading to a slightly steep learning curve. We therefore provided a working VAE model to make this workshop feasible.\n",
    "\n",
    "Here, we give an overview of the main components of the VAE model, and we do encourage you to have a look at the model files. They are given in the `scdynsys` folder:\n",
    "\n",
    "* `dynamic_vae.py`: this contains the main Python class defining our VAE. It has a `model` and a `guide` method, representing the model (including the decoder) and the variational distribution (which Pyro refers to as a \"guide\").\n",
    "* `dynamic_model.py`: this is the (solved) ODE model, which also has a `model` and `guide` method such that it can be integrated in the same variational inference loop.\n",
    "* `mixture_model.py`: As the name suggests: this defines the GMM.\n",
    "* `nets.py`: These are the encoder and decoder networks.\n",
    "\n",
    "### Methods of VAEgmmdyn\n",
    "\n",
    "```python\n",
    "# the init method...\n",
    "def __init__(data_dim, z_dim, hidden_dim, num_clus, ...):       \n",
    "    # initialize the PyroModule\n",
    "    super().__init__()\n",
    "\n",
    "    # define the encoder and decoder networks\n",
    "    self.decoder_x = DecoderX(\n",
    "        z_dim, \n",
    "        hidden_dim, \n",
    "        data_dim, \n",
    "    )\n",
    "    self.encoder_z = CondEncoderZ(\n",
    "        z_dim, \n",
    "        hidden_dim, \n",
    "        data_dim,\n",
    "    )\n",
    "\n",
    "    # define the mixture model\n",
    "    self.mix = GaussMix(z_dim, num_clus, weighted=False)\n",
    "\n",
    "    # define the dynamic model\n",
    "    self.dynamic_model = DynamicModel(num_clus)\n",
    "\n",
    "\n",
    "# the model method...\n",
    "def model(x, xtime, utime, ...):\n",
    "    # use GaussMix object to sample parameters for the mixture model\n",
    "    clus_locs, clus_chol_fact = self.mix()\n",
    "    # use the dynamic model to get time-dependent weights\n",
    "    weights = self.dynamic_model(utime)[..., xtime, :]\n",
    "    logweights = torch.log(weights + 1e-10)\n",
    "            \n",
    "    # plates indicate independence of samples\n",
    "    with pyro.plate(\"unobserved\", x.shape[-2]):\n",
    "        # setup a mixture model...\n",
    "        mix = dist.Categorical(logits=logweights)\n",
    "        comp = dist.MultivariateNormal(clus_locs, scale_tril=clus_chol_fact)\n",
    "        # and sample latent vectors.\n",
    "        z = pyro.sample(\"latent\", dist.MixtureSameFamily(mix, comp))\n",
    "\n",
    "    # decode the latent code z\n",
    "    x_loc, x_scale = self.decoder_x(z)\n",
    "            \n",
    "    with pyro.plate(\"xdata\", x.shape[-2]):\n",
    "        ## score reconstructed x against actual expression data\n",
    "        pyro.sample(\"xobs\", dist.Normal(x_loc, x_scale).to_event(1), obs=x)\n",
    "\n",
    "\n",
    "# the guide method\n",
    "def guide(x, xtime, utime, ...):\n",
    "    # use the guide method of GaussMix\n",
    "    clus_locs, clus_chol_fact = self.mix.guide()\n",
    "\n",
    "    # and the guide method of dynamic_model \n",
    "    weights = self.dynamic_model.guide(utime)\n",
    "        \n",
    "    # use the encoder to get the parameters used to define q(z|x)\n",
    "    z_loc, z_scale = self.encoder_z(x, utime[xtime])\n",
    "    \n",
    "    # sample latent vectors\n",
    "    with pyro.plate(\"unobserved\", x.shape[-2]):\n",
    "        # sample the latent code z\n",
    "        pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67d65d",
   "metadata": {},
   "source": [
    "### Method of the `DynamicModel` class\n",
    "\n",
    "This class samples initial values and rate parameters, and then \n",
    "solves the ODE model, and returns the time-dependent weights.\n",
    "For more complex models, you'd have to use a numerical ODE integrator...\n",
    "\n",
    "```python\n",
    "def __init__(self, num_clus, ...):\n",
    "    super().__init__()\n",
    "        \n",
    "    self.num_clus = num_clus\n",
    "    \n",
    "    # setup an auto-guide\n",
    "    self.auto_guide = AutoMultivariateNormal(\n",
    "        self, init_loc_fn=init_fn, init_scale=init_scale\n",
    "    )\n",
    "                \n",
    "    def forward(self, time: torch.Tensor) -> torch.Tensor:\n",
    "        # use a typical symmetric Dirichlet prior with concentration 0.5\n",
    "        halves = torch.full((self.num_clus,), 0.5, device=self.device)\n",
    "        X0 = pyro.sample(\"X0\", dist.Dirichlet(halves))\n",
    "\n",
    "        # and sample the off-diagonal elements of Q\n",
    "        shp_Q = (*X0.shape[:-1], self.num_clus-1, self.num_clus)\n",
    "        rate_Q = 10*torch.ones(shp_Q, device=self.device)\n",
    "        Qoffdiag = pyro.sample(\"Qoffdiag\", dist.Exponential(rate_Q).to_event(2))\n",
    "        \n",
    "        # solve the ODE explicitly using the matrix exponential:\n",
    "        #    Xt = exp(t*Q) * X0\n",
    "        Xt = dynamic_model(time, X0, Qoffdiag)\n",
    "        return Xt\n",
    "    \n",
    "    def guide(self, time: torch.Tensor) -> torch.Tensor:\n",
    "        # calls the auto-guide and returns the logweights using a HACK\n",
    "        guide_trace = poutine.trace(self.auto_guide).get_trace(time)\n",
    "        logweights = poutine.block(poutine.replay(self, guide_trace))(time)\n",
    "                \n",
    "        return logweights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b044b29",
   "metadata": {},
   "source": [
    "In this notebook (interactive python session), you might want to run cells multiple times. However, Pyro keeps track of your parameters in a so-called \"parameter store\". To reset all estimates, you can call the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear Pyro parameter store: erase any previously learned parameters\n",
    "\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb177ab",
   "metadata": {},
   "source": [
    "Next, we initialize the VAE model imported from `scdynsys.dynamic_vae.py`.\n",
    "\n",
    "Printing the vae gives an overview of all the components. Can you figure out what they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAEgmmdyn(\n",
    "    data_dim = data_dim, \n",
    "    z_dim = 3, \n",
    "    hidden_dim = 12,\n",
    "    num_clus = 4,\n",
    "    time_scaling = 0.5, # scale time axis for cond. encoder\n",
    "    use_cuda = USE_CUDA,\n",
    ")\n",
    "\n",
    "# print the model architecture:\n",
    "\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c340f",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Next, we'll define a function that fits the model to the sc data. The inputs are an `SVI` object, which we will define below, and contains the model and guide, and some details about what optimization methods and how to compute the ELBO (Pyro provides multiple options). \n",
    "\n",
    "Of course, we must also provide the data (including the timepoints) and the number of training iterations to use. The following function trains the model in the complete dataset at once, and does not use mini-batching. This works if you have a powerful GPU, but may be slow on the CPU or less capable computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop(\n",
    "    svi: SVI,\n",
    "    xs_raw: np.array,\n",
    "    xtime_raw: np.array,\n",
    "    utime_raw: np.array,\n",
    "    batch_size: int,\n",
    "    num_epochs: int,\n",
    ") -> tuple[list[tuple[int, float]], ...]:  \n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    # set up the data loader for mini-batch training\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': USE_CUDA}\n",
    "    xs_tens = torch.tensor(xs_raw, dtype=torch.float32)\n",
    "    xtime_tens = torch.tensor(xtime_raw, dtype=torch.long)\n",
    "    raw_data_combined = list(zip(xs_tens, xtime_tens))\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=raw_data_combined,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs\n",
    "    )\n",
    "\n",
    "    # the model requires the total number of samples N \n",
    "    # and unique time points utime\n",
    "\n",
    "    N = torch.tensor(len(data_loader.dataset), device=DEVICE)\n",
    "    utime = torch.tensor(utime_raw, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    # set up progress bar\n",
    "    trange = tqdm.notebook.trange\n",
    "    \n",
    "    # return loss list for convergence tracking\n",
    "    train_elbo = []\n",
    "    for epoch in (pbar := trange(num_epochs)):\n",
    "        epoch_loss = 0.0\n",
    "        for xs, ts in data_loader:\n",
    "            # do ELBO gradient and accumulate loss\n",
    "            epoch_loss += svi.step(xs.to(DEVICE), ts.to(DEVICE), utime, N)\n",
    "        total_epoch_loss = epoch_loss / len(data_loader)\n",
    "        train_elbo.append((epoch, total_epoch_loss))\n",
    "        pbar.set_description(f\"average train loss: {total_epoch_loss:0.2f}\")\n",
    "\n",
    "    return train_elbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7e364",
   "metadata": {},
   "source": [
    "### Now we can finally fit the model\n",
    "\n",
    "We have to choose some hyperparameters like batch size, number of epochs, \n",
    "and the learning rate (\"lr\"). \n",
    "\n",
    "The class JitTrace_ELBO is used to automatically compute the ELBO (and gradient).\n",
    "The \"Jit\" in the name stands for just-in-time and refers to \"just-in-time compilation\".\n",
    "This is a method to speed up runtime without using a more low-level programming language.\n",
    "HOWEVER: JIT requires very precise coding, and it is easy to break code that uses JIT.\n",
    "\n",
    "You'll see some warnings (that you can ignore) that are a testament to this tedious \n",
    "JIT-compatible programming.\n",
    "\n",
    "If `JitTrace_ELBO` does not work, try using `Trace_ELBO` instead. This is slower but more forgiving.\n",
    "\n",
    "**Skip this step if you don't want to wait! We also included a pre-trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11364383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using mini-batch training\n",
    "\n",
    "# setup data loaders\n",
    "BATCH_SIZE = 2**10\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": 2e-3}\n",
    "optimizer = Adam(adam_args)\n",
    "# setup the inference algorithm\n",
    "loss_method = JitTrace_ELBO(num_particles=10, vectorize_particles=True)\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=loss_method)\n",
    "\n",
    "# START TRAINING!!!\n",
    "elbo_loss = train_test_loop(\n",
    "    svi,\n",
    "    xs_raw,\n",
    "    xtime_raw,\n",
    "    utime_raw,\n",
    "    BATCH_SIZE,\n",
    "    NUM_EPOCHS\n",
    ")\n",
    "\n",
    "# plot the training and test loss curves\n",
    "train_elbo_vals = [x[1] for x in elbo_loss]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "ax.plot(train_elbo_vals, linewidth=0.5, color='k', label='Train ELBO')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the trained model parameters, uncomment the following line:\n",
    "# pyro.get_param_store().save(\"../data/vae_dyn_model_params.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf36f82",
   "metadata": {},
   "source": [
    "### Load a pre-trained model\n",
    "\n",
    "As training might take 20 minutes, depending on your hardware,\n",
    "we've included a pre-trained model. We do advise to also run the training loop,\n",
    "even for a smaller number of epochs. You'll see that the model does not always converge\n",
    "to the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load pre-fitted model\n",
    "\n",
    "# HACK:\n",
    "# register safe globals for loading, account for recent torch/pyro changes\n",
    "torch.serialization.add_safe_globals([\n",
    "    torch.distributions.constraints._Real,\n",
    "    pyro.distributions.constraints._SoftplusPositive,\n",
    "    pyro.distributions.constraints._UnitLowerCholesky,\n",
    "])\n",
    "\n",
    "# load the trained model parameters\n",
    "store = pyro.get_param_store()\n",
    "store.clear()\n",
    "param_file = \"../data/vae_dyn_model_params.pt\"\n",
    "store.load(param_file, map_location=DEVICE)\n",
    "\n",
    "# load parameters into model\n",
    "state_dict = vae.state_dict()\n",
    "state_dict.update({k : store[k] for k in state_dict if k in store})\n",
    "vae.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16eb87a",
   "metadata": {},
   "source": [
    "## 3. Visualize the results\n",
    "\n",
    "We'll first have a look at the latent space embedding the model came up with. As our latent space is 3D, we can easily project this to 2D graphics, using PCA to get the most informative projection first (i.e. the first 2 PCs).\n",
    "\n",
    "We can also use the VAE model to classify cells: the GMM components correspond to clusters, and for each cell we can probabilistically sample a cluster that the cell belongs to. This is probabilistic, as the GMM components have overlap, and so for intermediate cell states, we can't be quite sure which cluster the cell belongs to.\n",
    "\n",
    "One important issue with GMMs is that due to random initialization of the NN weights and the centers of the GMM components, we can't know a priori which cluster (0, 1, 2, 3) is going to belong to which cell type (T1, T2, MZ, FM). \n",
    "At this point, we might look at the mean marker expression of clusters, and link clusters to meaningful cell types. In our case with simulated data, we can just compare the inferred cluster with the ground truth cell type, and come up with a matching between them. For example: 0 -> T2, 1 -> MZ, 2 -> T1, 3 -> FM.\n",
    "\n",
    "For visualization in cells below, we define a `permutation` such that we can re-order model output to match with the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## infer cell types \n",
    "\n",
    "# get the latent space representation of all cells\n",
    "zs_tensor = vae.dimension_reduction(xs_tensor, ts_tensor).cpu()\n",
    "zs_raw = zs_tensor.numpy()\n",
    "\n",
    "# do PCA on the latent space\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(zs_raw)\n",
    "zs_pca = pca.transform(zs_raw)\n",
    "\n",
    "# the VAEgmmdyn class has a classifier method to assign clusters to cells\n",
    "with torch.no_grad():\n",
    "    clus = vae.classifier(xs_tensor, ts_tensor)\n",
    "clus = clus.cpu().numpy()\n",
    "\n",
    "# find the ground truth cell types that are most represented in each inferred cluster\n",
    "# make a dictionary to translate cluster indices to cell type names\n",
    "translation_dict = {}\n",
    "\n",
    "for clus_idx in range(vae.num_clus):\n",
    "    # find overlap between inferred clusters and ground truth cell types\n",
    "    celltype_counts = {\n",
    "        ct : np.sum((clus == clus_idx) & (celltypes == ct))\n",
    "        for ct in celltypes_unique\n",
    "    }\n",
    "    # find the most common cell type in this cluster\n",
    "    most_common_ct = max(celltype_counts, key=celltype_counts.get)\n",
    "    count = celltype_counts[most_common_ct]\n",
    "    print(f\"Cluster {clus_idx}: most common cell type: {most_common_ct} ({count} cells)\")\n",
    "    translation_dict[clus_idx] = most_common_ct\n",
    "\n",
    "# map inferred cluster indices to cell type names\n",
    "clus_names = [translation_dict[clus_idx] for clus_idx in clus]\n",
    "\n",
    "# define a permutation of cluster indices based on alphabetical \n",
    "# order of cell type names\n",
    "permutation = sorted(translation_dict.keys(), key=lambda k: translation_dict[k])\n",
    "\n",
    "# re-index clusters to have consistent colors\n",
    "new_clus = np.zeros_like(clus)\n",
    "for new_idx, clus_idx in enumerate(permutation):\n",
    "    new_clus[clus == clus_idx] = new_idx\n",
    "clus = new_clus\n",
    "\n",
    "# define a color for each cell based on inferred cell type\n",
    "cols = [cell_type_colors[nm] for nm in clus_names]\n",
    "\n",
    "# visualize inferred cell types in PCA space\n",
    "fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "\n",
    "ax = axs[0, 0]\n",
    "ax.scatter(zs_pca[:, 0], zs_pca[:, 1], s=3, linewidths=0, c=cols)\n",
    "ax.set(xlabel='PCA 1', ylabel='PCA 2')\n",
    "ax = axs[1, 0]\n",
    "ax.scatter(zs_pca[:, 0], zs_pca[:, 2], s=3, linewidths=0, c=cols)\n",
    "ax.set(xlabel='PCA 1', ylabel='PCA 3')\n",
    "ax = axs[0, 1]\n",
    "ax.scatter(zs_pca[:, 2], zs_pca[:, 1], s=3, linewidths=0, c=cols)\n",
    "ax.set(xlabel='PCA 3', ylabel='PCA 2')\n",
    "\n",
    "axs[1, 1].set_visible(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf87d0f",
   "metadata": {},
   "source": [
    "### Inspect parameter estimates\n",
    "\n",
    "Next, we'll check what parameter values we actually estimated.\n",
    "The dynamical model is quite simple and containst only initial values ($X_0$)\n",
    "and differentiation rates $Q_{ij}$ with $i \\neq j $ (called `Qoffdiag` in the model).\n",
    "\n",
    "We will use the `Predictive` class from Pyro to simulate our model, and sample from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample Q and X0 values from the fitted model\n",
    "\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "# setup the Predictive object to sample from the posterior\n",
    "predictive = Predictive(\n",
    "    vae.model, guide=vae.guide, num_samples=100, \n",
    "    return_sites=[\"X0\", \"Qoffdiag\"],\n",
    "    parallel=True\n",
    ")\n",
    "\n",
    "# sample from the posterior distribution\n",
    "samples = predictive(\n",
    "    xs_tensor, \n",
    "    xtime_tensor, \n",
    "    utime_tensor, \n",
    "    N=torch.tensor(n_samples, device=DEVICE)\n",
    ")\n",
    "\n",
    "# extract Q and X0 samples\n",
    "Qoffdiag_samples = samples[\"Qoffdiag\"].cpu().numpy().squeeze()\n",
    "weights_samples = samples[\"X0\"].cpu().numpy().squeeze()\n",
    "\n",
    "# apply the permutation to the Q matrices and weights\n",
    "weights_samples_permuted = weights_samples[:, permutation]\n",
    "\n",
    "# (we'll do this permutation for Q matrices below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6bee9",
   "metadata": {},
   "source": [
    "Plot the values of $X_0$ (the initial consitions)\n",
    "together with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "\n",
    "# plot violin plots of inferred initial weights\n",
    "violins = ax.violinplot(\n",
    "    weights_samples_permuted, \n",
    "    showmeans=False, showextrema=False\n",
    ")\n",
    "for pc in violins['bodies']:\n",
    "    pc.set(facecolor='k', alpha=1)\n",
    "\n",
    "ax.set(xlabel=\"cell type\", ylabel=\"Fraction\", \n",
    "       title=\"Initial conditions $X_0$\")\n",
    "\n",
    "# compare with true weights at time 0\n",
    "cts_t0 = dataset[dataset['Timepoint'] == utime_raw[0]]['CellType'].values\n",
    "\n",
    "true_weights = [\n",
    "    np.sum(cts_t0 == ct) / len(cts_t0) \n",
    "    for ct in sorted(celltypes_unique)\n",
    "]\n",
    "\n",
    "pos = np.arange(1, vae.num_clus + 1)\n",
    "ax.scatter(pos, true_weights, s=10, color='red', \n",
    "           label='True Weights', zorder=1)\n",
    "\n",
    "ax.set_xticks(pos)\n",
    "ax.set_xticklabels(celltypes_unique)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedad838",
   "metadata": {},
   "source": [
    "### Plot the Q matrix\n",
    "\n",
    "We've saved the ground truth differentiation rates in a file in the data folder.\n",
    "Let's see how well we were able to reconstruct these values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scdynsys.dynamic_model import build_Q_mat\n",
    "\n",
    "# import ground truth Q matrix\n",
    "\n",
    "file_Q = '../data/simulated_time_series_Q_matrix.csv'\n",
    "Q_gt = pd.read_csv(file_Q, index_col=0).values\n",
    "\n",
    "# set diagonal entries to zero for better visualization\n",
    "np.fill_diagonal(Q_gt, 0.0)\n",
    "\n",
    "# plot the inferred Q\n",
    "Qoffdiag_samples = samples[\"Qoffdiag\"].cpu().squeeze()\n",
    "Q_samples = build_Q_mat(Qoffdiag_samples).numpy()\n",
    "\n",
    "# apply permutation to Q matrices\n",
    "# (to match inferred clusters to ground truth cell types)\n",
    "Q_samples_permuted = Q_samples[:, permutation, :][:, :, permutation]\n",
    "\n",
    "meanQ = np.mean(Q_samples_permuted, axis=0)\n",
    "# set diagonal entries to zero \n",
    "np.fill_diagonal(meanQ, 0)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "ax = axs[0]\n",
    "im = ax.pcolor(meanQ, cmap='hot', vmin=0, vmax=np.max(Q_gt))\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "# plot the ground true Q matrix for comparison\n",
    "ax = axs[1]\n",
    "im = ax.pcolor(Q_gt, cmap='hot', vmin=0, vmax=np.max(Q_gt))\n",
    "fig.colorbar(im, ax=ax)\n",
    "\n",
    "axs[0].set_title(\"Inferred Q matrix\")\n",
    "axs[1].set_title(\"Ground Truth Q matrix\")\n",
    "\n",
    "# set axis labels and ticks: cell type names\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"From Cluster\")\n",
    "    ax.set_ylabel(\"To Cluster\")\n",
    "    ticks = np.arange(0.5, vae.num_clus + 0.5)\n",
    "    ax.set(xticks=ticks, yticks=ticks)\n",
    "    ax.set(xticklabels=(ctu:=celltypes_unique), yticklabels=ctu)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203db6fa",
   "metadata": {},
   "source": [
    "### Timecourse of latent space\n",
    "\n",
    "Next, we will plot the latent cell distributions as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot latents space embeddings for each time points\n",
    "\n",
    "zs_tensor = vae.dimension_reduction(xs_tensor, ts_tensor).cpu()\n",
    "zs_raw = zs_tensor.numpy()\n",
    "\n",
    "# do PCA on the latent space\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(zs_raw)\n",
    "zs_pca = pca.transform(zs_raw)\n",
    "\n",
    "# plot PCA 1 and 2 in different panels as a function of time\n",
    "fig, axs = plt.subplots(\n",
    "    3, num_timepoints, figsize=(3*num_timepoints, 9), \n",
    "    sharey=True, sharex=True\n",
    ")\n",
    "\n",
    "# prepare colors for splitting by time point\n",
    "cols_array = np.array(cols)\n",
    "\n",
    "for t_idx in range(num_timepoints):\n",
    "    ax1, ax2, ax3 = axs[:, t_idx]\n",
    "    time_mask = (xtime_raw == t_idx)\n",
    "    ax1.scatter(zs_pca[time_mask, 0], zs_pca[time_mask, 1], s=2, alpha=1,\n",
    "                   linewidths=0, c=cols_array[time_mask])\n",
    "    ax2.scatter(zs_pca[time_mask, 0], zs_pca[time_mask, 2], s=2, alpha=1,\n",
    "                   linewidths=0, c=cols_array[time_mask])\n",
    "    ax3.scatter(zs_pca[time_mask, 2], zs_pca[time_mask, 1], s=2, alpha=1,\n",
    "                   linewidths=0, c=cols_array[time_mask])\n",
    "    ax1.set_title(f'Time {utime_raw[t_idx]}')\n",
    "    ax1.set(xlabel='PCA 1', ylabel='PCA 2')\n",
    "    ax2.set(xlabel='PCA 1', ylabel='PCA 3')\n",
    "    ax3.set(xlabel='PCA 3', ylabel='PCA 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5db49f",
   "metadata": {},
   "source": [
    "### Plot the inferred trajectories\n",
    "\n",
    "In addition to the time-dependent latent space plot above,\n",
    "we can also look how well the inferred trajectories correspond with\n",
    "the ground truth. We saved the simulated trajectories in a file\n",
    "in the data folder.\n",
    "\n",
    "The `VAEgmmdyn` class provides a method to simulate trajecties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ground truth weights for comparison\n",
    "\n",
    "file = '../data/simulated_time_series_ground_truth_weights.csv'\n",
    "ground_truth_weights = pd.read_csv(file)\n",
    "\n",
    "# simulate trajectories from the fitted model\n",
    "ws_samples = vae.sample_trajectories(\n",
    "    n=100, ts=utime_tensor, \n",
    ")\n",
    "\n",
    "# convert to numpy array\n",
    "ws_samples_raw = ws_samples.cpu().numpy()\n",
    "\n",
    "# apply permutation to the weights\n",
    "ws_samples_raw = ws_samples_raw[:, :, permutation]\n",
    "\n",
    "# compute mean and credible intervals\n",
    "mean_ws = np.mean(ws_samples_raw, axis=0)\n",
    "lower_ws = np.percentile(ws_samples_raw, 5, axis=0)\n",
    "upper_ws = np.percentile(ws_samples_raw, 95, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "for i in range(vae.num_clus):\n",
    "    ct = translation_dict[permutation[i]]\n",
    "    ct_color = cell_type_colors[ct]\n",
    "    ax.plot(utime_raw, mean_ws[:, i], label=ct, color=ct_color)\n",
    "    ax.fill_between(utime_raw, lower_ws[:, i], upper_ws[:, i], \n",
    "                    color=ct_color, alpha=0.3)\n",
    "\n",
    "    ax.scatter(ground_truth_weights['Timepoint'], \n",
    "               ground_truth_weights[f'Cluster_{i}_Weight'],\n",
    "               color=ct_color, marker='x')\n",
    "    \n",
    "ax.set(xlabel=\"Time\", ylabel=\"Cluster Weights\")\n",
    "ax.set_title(\"Inferred GMM Cluster Weights over Time\")\n",
    "\n",
    "# add ground truth legend\n",
    "ax.scatter([], [], color='k', marker='x', label='Ground Truth')\n",
    "\n",
    "ax.legend(fontsize='small', loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a1949",
   "metadata": {},
   "source": [
    "### Show differentiation pathways between clusters\n",
    "\n",
    "Next, we will give a visual representation of how cells develop. For this, we will plot the cluster centers (locations) in the latent space (after applying PCA),\n",
    "together with arrows indicating differentiation between the cell types.\n",
    "\n",
    "This is essentially the same information of the Q matrix plots above,\n",
    "but of you'd have more clusters, you could investigate how cell populations\n",
    "differentiate to neighboring (or distant) other cell types. \n",
    "Here distance is defined in the latent cell state space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a diagram with differentation rates and\n",
    "# the cluster locations in latent space\n",
    "\n",
    "loc_pred = Predictive(vae.mix, guide=vae.mix.guide,\n",
    "                      num_samples=100, parallel=True, \n",
    "                      return_sites=[\"clus_locs\"])\n",
    "loc_samples = loc_pred()[\"clus_locs\"].cpu().numpy()\n",
    "\n",
    "# apply the PCA transformation to the loc samples\n",
    "locs_pca = pca.transform(loc_samples.reshape(-1, vae.z_dim))\n",
    "locs_pca = locs_pca.reshape(-1, vae.num_clus, vae.z_dim)\n",
    "\n",
    "# create the plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# plot the estimated arrows between the cluster centers in PCA space\n",
    "ax = axs[0]\n",
    "\n",
    "# aux function to plot locs in PCA space\n",
    "def plot_locs(ax, locs_pca):\n",
    "    for i in range(vae.num_clus):\n",
    "        ct = translation_dict[permutation[i]]\n",
    "        ct_color = cell_type_colors[ct]\n",
    "        ax.scatter(locs_pca[:, i, 0], locs_pca[:, i, 1], s=5, alpha=0.5,\n",
    "                color=ct_color, label=ct)\n",
    "        \n",
    "    ax.set(xlabel=\"PCA 1\", ylabel=\"PCA 2\")\n",
    "    ax.legend(fontsize='small')\n",
    "\n",
    "plot_locs(axs[0], locs_pca)\n",
    "\n",
    "# plot arrows between the locs according to the Q matrix\n",
    "Q_mean = Q_samples_permuted.mean(axis=0)\n",
    "\n",
    "# aux function to plot arrows\n",
    "def plot_arrows(ax, Q_mean, locs_pca, threshold=0.05):\n",
    "    for i in range(vae.num_clus):\n",
    "        for j in range(vae.num_clus):\n",
    "            if i == j or Q_mean[i, j] <= threshold:\n",
    "                continue\n",
    "            start = np.mean(locs_pca[:, i, 0]), np.mean(locs_pca[:, i, 1])\n",
    "            end = np.mean(locs_pca[:, j, 0]), np.mean(locs_pca[:, j, 1])\n",
    "            # make sure that the width of the arrows \n",
    "            # is proportional to the Q values\n",
    "            ap =dict(\n",
    "                arrowstyle=\"->\", color='k', lw=Q_mean[i, j]*5,\n",
    "                shrinkA=10, shrinkB=10, connectionstyle=\"arc3,rad=0.1\"\n",
    "            )\n",
    "            # plot the arrow\n",
    "            ax.annotate(\n",
    "                \"\",\n",
    "                xy=start, xycoords='data',\n",
    "                xytext=end, textcoords='data',\n",
    "                arrowprops=ap\n",
    "            )\n",
    "\n",
    "plot_arrows(axs[0], Q_mean, locs_pca)\n",
    "\n",
    "# now plot the ground truth arrows\n",
    "\n",
    "plot_locs(axs[1], locs_pca)\n",
    "plot_arrows(axs[1], Q_gt, locs_pca)\n",
    "\n",
    "axs[0].set_title(\"inferred differentiation rates\")\n",
    "axs[1].set_title(\"ground truth differentiation rates\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f942253",
   "metadata": {},
   "source": [
    "## 4. Restrict possible differentiation pathways. \n",
    "\n",
    "As you can see in the above diagram, The model predicts differentiation pathways that we did not put into the simulated data. Our fitted model allows for $4\\times 3 = 12$ possible differentiation pairs (even loops). \n",
    "\n",
    "This freedom might not be biologically plausible, and maybe you have some information to restrict some of these pathways. The goal is to put such restrictions in the model. \n",
    "\n",
    "The simplest way to do this is to multiply the matrix $Q$ with a binary \"mask\" matrix $M$, with a 1 indicating that a path is allowed and a 0 that it is not feasible. Note that the multiplication of $Q$ and $M$ is elementwise.\n",
    "\n",
    "1. Modify the dynamical model to accept a mask matrix $M$.\n",
    "2. Add the mask $M$ to the initialization function of the VAE, and make sure it finds it's way to the right functions.\n",
    "3. Figure out which index pair of $M$ correspond with a cluster index in the model. What happens if you reset parameters and fit the restricted model directly?\n",
    "4. Experiment with first fitting the unrestricted model ($M_{ij} = 1$), and then re-fitting with a different $M$. \n",
    "5. Compare different resticted models in terms of ELBO and goodness of fit (visually). Can you find/select the best fitting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ea3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e5702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
