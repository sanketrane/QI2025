{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ac4612",
   "metadata": {
    "papermill": {
     "duration": 0.003955,
     "end_time": "2025-10-23T17:03:07.116440",
     "exception": false,
     "start_time": "2025-10-23T17:03:07.112485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cell-Wise Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e3dbe",
   "metadata": {
    "papermill": {
     "duration": 0.003227,
     "end_time": "2025-10-23T17:03:07.123336",
     "exception": false,
     "start_time": "2025-10-23T17:03:07.120109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following model is trained on 20-day-old mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acab2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:07.137652Z",
     "iopub.status.busy": "2025-10-23T17:03:07.137316Z",
     "iopub.status.idle": "2025-10-23T17:03:11.472676Z",
     "shell.execute_reply": "2025-10-23T17:03:11.471891Z"
    },
    "papermill": {
     "duration": 4.340888,
     "end_time": "2025-10-23T17:03:11.473971",
     "exception": false,
     "start_time": "2025-10-23T17:03:07.133083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from itertools import cycle\n",
    "\n",
    "from models import Cell_Wise_VAE, VAE_Single_Dataset\n",
    "import pickle\n",
    "import umap.umap_ as umap\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b582d",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cabe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = pd.read_csv(\"./cellwiseVAE_workshop.csv\")\n",
    "mod1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16913a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:11.497954Z",
     "iopub.status.busy": "2025-10-23T17:03:11.497738Z",
     "iopub.status.idle": "2025-10-23T17:03:12.311273Z",
     "shell.execute_reply": "2025-10-23T17:03:12.310455Z"
    },
    "papermill": {
     "duration": 0.826777,
     "end_time": "2025-10-23T17:03:12.312639",
     "exception": false,
     "start_time": "2025-10-23T17:03:11.485862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MinMaxScler rescales features to the range [0,1]\n",
    "# It matches sigmoid() activation from model definition\n",
    "\n",
    "scaler_mod1 = MinMaxScaler()\n",
    "X = mod1.drop(columns=['sample_id','cell_type'])\n",
    "X = scaler_mod1.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=mod1.drop(columns=['sample_id','cell_type']).columns)\n",
    "X['sample_id'] = mod1['sample_id'].values\n",
    "X['cell_type'] = mod1['cell_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler to disk so that the same scaling operation can be applied later\n",
    "with open('./scaler_mod1.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_mod1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873e066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:12.382852Z",
     "iopub.status.busy": "2025-10-23T17:03:12.382633Z",
     "iopub.status.idle": "2025-10-23T17:03:12.395874Z",
     "shell.execute_reply": "2025-10-23T17:03:12.395087Z"
    },
    "papermill": {
     "duration": 0.020133,
     "end_time": "2025-10-23T17:03:12.396569",
     "exception": false,
     "start_time": "2025-10-23T17:03:12.376436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting final features and labels into arrays\n",
    "features_1 = X.drop(columns=[\"sample_id\", \"cell_type\"]).values\n",
    "cell_types_1 = X[\"cell_type\"].values\n",
    "sample_ids_1 = X[\"sample_id\"].values\n",
    "\n",
    "# Number of features going into the VAE\n",
    "num_features = features_1.shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285eb30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:12.404780Z",
     "iopub.status.busy": "2025-10-23T17:03:12.404557Z",
     "iopub.status.idle": "2025-10-23T17:03:12.495325Z",
     "shell.execute_reply": "2025-10-23T17:03:12.494709Z"
    },
    "papermill": {
     "duration": 0.095677,
     "end_time": "2025-10-23T17:03:12.496066",
     "exception": false,
     "start_time": "2025-10-23T17:03:12.400389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose GPU, if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f032dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:12.508825Z",
     "iopub.status.busy": "2025-10-23T17:03:12.508722Z",
     "iopub.status.idle": "2025-10-23T17:03:12.512219Z",
     "shell.execute_reply": "2025-10-23T17:03:12.511739Z"
    },
    "papermill": {
     "duration": 0.013365,
     "end_time": "2025-10-23T17:03:12.513268",
     "exception": false,
     "start_time": "2025-10-23T17:03:12.499903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main loss function for the VAE\n",
    "def mmvae_loss_function(recons, truths, kl_loss, beta=1.0, device=\"cuda\"):\n",
    "\n",
    "    recon_losses = {} # Per-Modality Reconstruction Losses\n",
    "    recon_loss_total = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # Looping through the modalities (trivial for single-modality)\n",
    "    for mod in truths.keys():\n",
    "\n",
    "        # Ensuring computations proceed only for existing modalities\n",
    "        if mod in recons:\n",
    "            # Ensuring both tensors have the same batch size\n",
    "            n = min(recons[mod].shape[0], truths[mod].shape[0])\n",
    "            recon = recons[mod][:n]\n",
    "            truth = truths[mod][:n]\n",
    "\n",
    "            # MSE reconstruction loss (averaged per batch)\n",
    "            loss_mod = F.mse_loss(recon, truth, reduction='mean')\n",
    "            recon_losses[mod] = loss_mod\n",
    "            recon_loss_total += loss_mod\n",
    "\n",
    "    # Total VAE loss = reconstruction + beta * KL\n",
    "    total_loss = recon_loss_total + beta * kl_loss\n",
    "\n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'kl_loss': kl_loss,\n",
    "        'recon_loss_total': recon_loss_total,\n",
    "        'recon_losses': recon_losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c363b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:12.527572Z",
     "iopub.status.busy": "2025-10-23T17:03:12.527454Z",
     "iopub.status.idle": "2025-10-23T17:03:13.314409Z",
     "shell.execute_reply": "2025-10-23T17:03:13.313569Z"
    },
    "papermill": {
     "duration": 0.794182,
     "end_time": "2025-10-23T17:03:13.315741",
     "exception": false,
     "start_time": "2025-10-23T17:03:12.521559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stratified train/validation split\n",
    "\n",
    "# Create a combined label that ensures each (cell_type, sample_id) group is proportionally represented\n",
    "# The same logic applies to both train and validation sets\n",
    "combined_strata_x1 = [f\"{cell}_{sample}\" for cell, sample in zip(cell_types_1, sample_ids_1)]\n",
    "\n",
    "# Stratified split (preserving the distribution)\n",
    "train_idx_x1, val_idx_x1 = train_test_split(np.arange(len(features_1)), test_size=0.2, stratify=combined_strata_x1, shuffle=True)\n",
    "\n",
    "train_x1 = features_1[train_idx_x1]\n",
    "val_x1 = features_1[val_idx_x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b447b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:13.333607Z",
     "iopub.status.busy": "2025-10-23T17:03:13.333504Z",
     "iopub.status.idle": "2025-10-23T17:03:13.361724Z",
     "shell.execute_reply": "2025-10-23T17:03:13.361425Z"
    },
    "papermill": {
     "duration": 0.038407,
     "end_time": "2025-10-23T17:03:13.362976",
     "exception": false,
     "start_time": "2025-10-23T17:03:13.324569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loader (cycled for infinite iteration during training loops)\n",
    "# This helps extend the logic to multiple modalities and prevents the StopIteration Error\n",
    "train_loader_x1 = DataLoader(VAE_Single_Dataset(train_x1), batch_size=128, shuffle=True)\n",
    "# Number of steps per epoch\n",
    "num_steps = len(train_loader_x1)\n",
    "train_loader_x1 = cycle(train_loader_x1)\n",
    "\n",
    "# Validation loader\n",
    "val_loader_x1 = DataLoader(VAE_Single_Dataset(val_x1), batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61eaa7",
   "metadata": {},
   "source": [
    "## VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cce58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:03:13.403097Z",
     "iopub.status.busy": "2025-10-23T17:03:13.402848Z",
     "iopub.status.idle": "2025-10-23T19:35:40.712175Z",
     "shell.execute_reply": "2025-10-23T19:35:40.711373Z"
    },
    "papermill": {
     "duration": 9147.316739,
     "end_time": "2025-10-23T19:35:40.713551",
     "exception": false,
     "start_time": "2025-10-23T17:03:13.396812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the Cell_Wise_VAE model and move it to the selected device (GPU/CPU)\n",
    "model = Cell_Wise_VAE(input_dim=15, latent_dim=3, use_mean=True).to(device)\n",
    "print(\"using device : \", device)\n",
    "print(\"latent dim: \", model.latent_dim)\n",
    "\n",
    "# Training Hyperparameters\n",
    "num_epochs = 100\n",
    "BETA = 0.001 # KL weight (beta-penalty)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=150, gamma=0.5)\n",
    "\n",
    "# Lists for storing performance metrics over epochs\n",
    "train_losses, train_recon_totals, train_kl_losses = [], [], []\n",
    "val_losses, val_recon_totals, val_kl_losses = [], [], []\n",
    "\n",
    "# Dictionaries for storing reconstruction losses per modality\n",
    "train_recon_losses_mod = {\"mod1\": []}\n",
    "val_recon_losses_mod = {\"mod1\": []}\n",
    "\n",
    "#################\n",
    "# Training Loop #\n",
    "#################\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start = time.time()\n",
    "    model.train() # Set model to training mode\n",
    "\n",
    "    # Running sums for the epoch\n",
    "    epoch_total_loss, epoch_recon_loss, epoch_kl_loss = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Tracking per-modality averages\n",
    "    train_mod_sums = {m: 0.0 for m in train_recon_losses_mod}\n",
    "    train_mod_counts = {m: 0 for m in train_recon_losses_mod}\n",
    "\n",
    "    ##################\n",
    "    # Training Steps #\n",
    "    ##################\n",
    "    for step in range(num_steps):\n",
    "        # Get the next training batch from the infinite iterator\n",
    "        x1 = next(train_loader_x1)[0].to(device)\n",
    "\n",
    "        # Forward pass through the VAE\n",
    "        optimizer.zero_grad()\n",
    "        # Reconstructed outputs for each modality and KL divergence term for the latent distribution\n",
    "        recons, kl_loss, _, _ = model(x1=x1)\n",
    "        # Ground-Truth tensors for reconstruction\n",
    "        truths = {\"mod1\": x1}\n",
    "\n",
    "        # Computing the VAE loss (reconstruction + beta * KL)\n",
    "        losses = mmvae_loss_function(recons, truths, kl_loss, beta=BETA, device=device)\n",
    "        total_loss = losses[\"total_loss\"]\n",
    "\n",
    "        # Backpropagation\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Storing the step losses\n",
    "        epoch_total_loss += total_loss.item()\n",
    "        epoch_recon_loss += losses[\"recon_loss_total\"].item()\n",
    "        epoch_kl_loss += losses[\"kl_loss\"].item()\n",
    "\n",
    "        # Accumulating per-modality reconstruction loss\n",
    "        for mod, val in losses[\"recon_losses\"].items():\n",
    "            train_mod_sums[mod] += val.item()\n",
    "            train_mod_counts[mod] += 1\n",
    "\n",
    "    # Averaging over all the steps executed in an epoch\n",
    "    epoch_total_loss /= num_steps\n",
    "    epoch_recon_loss /= num_steps\n",
    "    epoch_kl_loss /= num_steps\n",
    "\n",
    "    # Saving the epoch metrics\n",
    "    train_losses.append(epoch_total_loss)\n",
    "    train_recon_totals.append(epoch_recon_loss)\n",
    "    train_kl_losses.append(epoch_kl_loss)\n",
    "\n",
    "    ####################\n",
    "    # Validation Steps #\n",
    "    ####################\n",
    "    model.eval()\n",
    "    val_mod_sums = {\"mod1\": 0.0}\n",
    "    val_mod_counts = {\"mod1\": 0}\n",
    "    val_kl_sums = {\"mod1\": 0.0}\n",
    "    val_kl_counts = {\"mod1\": 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Iterating through all the modalities (only one in this example)\n",
    "        for mod_name, (x_name, loader) in zip([\"mod1\"], [(\"x1\", val_loader_x1)]):\n",
    "            for batch in loader:\n",
    "                batch = batch[0].to(device)\n",
    "\n",
    "                # Forward pass depending on the modality considered\n",
    "                if x_name == \"x1\":\n",
    "                    recons, kl_loss, _, _ = model(x1=batch)\n",
    "\n",
    "                truths = {mod_name: batch}\n",
    "                # Computing the validation loss\n",
    "                losses = mmvae_loss_function(recons=recons,truths=truths,kl_loss=kl_loss,beta=BETA,device=device)\n",
    "\n",
    "                val_mod_sums[mod_name] += losses[\"recon_loss_total\"].item()\n",
    "                val_mod_counts[mod_name] += 1\n",
    "                val_kl_sums[mod_name] += losses[\"kl_loss\"].item()\n",
    "                val_kl_counts[mod_name] += 1\n",
    "\n",
    "    # Computing the average validation metrics per modality\n",
    "    avg_per_mod_recon = {}\n",
    "    for mod in val_mod_sums:\n",
    "        if val_mod_counts[mod] > 0:\n",
    "            avg_per_mod_recon[mod] = val_mod_sums[mod] / val_mod_counts[mod]\n",
    "        else:\n",
    "            avg_per_mod_recon[mod] = np.nan\n",
    "\n",
    "    avg_per_mod_kl = {}\n",
    "    for mod in val_kl_sums:\n",
    "        if val_kl_counts[mod] > 0:\n",
    "            avg_per_mod_kl[mod] = val_kl_sums[mod] / val_kl_counts[mod]\n",
    "        else:\n",
    "            avg_per_mod_kl[mod] = np.nan\n",
    "\n",
    "    # Computing the total validation loss for this epoch\n",
    "    val_recon_total_epoch = np.sum(list(avg_per_mod_recon.values()))\n",
    "    val_kl_total_epoch = np.sum(list(avg_per_mod_kl.values()))\n",
    "    val_total_loss_epoch = val_recon_total_epoch + BETA * val_kl_total_epoch\n",
    "\n",
    "    # Storing the metrics\n",
    "    val_losses.append(val_total_loss_epoch)\n",
    "    val_recon_totals.append(val_recon_total_epoch)\n",
    "    val_kl_losses.append(val_kl_total_epoch)\n",
    "\n",
    "    # Step learning-rate scheduler\n",
    "    scheduler.step()\n",
    "    stop = time.time()\n",
    "\n",
    "    # Printing out the results for this epoch\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | time {stop - start:.2f}s\")\n",
    "    print(f\"Train: Total={epoch_total_loss:.6f} | Recon={epoch_recon_loss:.6f} | KL={epoch_kl_loss:.6f}\")\n",
    "    print(f\" Val : Total={val_total_loss_epoch:.6f} | Recon={val_recon_total_epoch:.6f} | KL={val_kl_total_epoch:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee04df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T19:35:40.788148Z",
     "iopub.status.busy": "2025-10-23T19:35:40.787719Z",
     "iopub.status.idle": "2025-10-23T19:35:40.850176Z",
     "shell.execute_reply": "2025-10-23T19:35:40.849865Z"
    },
    "papermill": {
     "duration": 0.085788,
     "end_time": "2025-10-23T19:35:40.850699",
     "exception": false,
     "start_time": "2025-10-23T19:35:40.764911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode, ensuring deterministic behavior\n",
    "model.eval()\n",
    "\n",
    "# Plotting the total loss curves over epochs for both training and validation\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba4e94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T19:35:40.896690Z",
     "iopub.status.busy": "2025-10-23T19:35:40.896592Z",
     "iopub.status.idle": "2025-10-23T19:35:41.018853Z",
     "shell.execute_reply": "2025-10-23T19:35:41.018358Z"
    },
    "papermill": {
     "duration": 0.14567,
     "end_time": "2025-10-23T19:35:41.019372",
     "exception": true,
     "start_time": "2025-10-23T19:35:40.873702",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the KL divergence component over epochs\n",
    "plt.plot(train_kl_losses, label=\"Train KLD Loss\", color=\"black\")\n",
    "plt.plot(val_kl_losses, label=\"Val KLD Loss\", color=\"gray\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"KL: Training Losse\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a707b46b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Latent-Space Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423ecc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:40.165066Z",
     "iopub.status.busy": "2025-09-05T06:54:40.164788Z",
     "iopub.status.idle": "2025-09-05T06:54:40.168862Z",
     "shell.execute_reply": "2025-09-05T06:54:40.168351Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_latent_space_by_mod_column_mod1(model, sampled_df, feature_columns):\n",
    "    \"\"\"\n",
    "    Helper function running the encoder and returning a dataframe of latent means for the considered modality.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latent_dfs = []\n",
    "\n",
    "    # Mapping the modality name to the corresponding encoder component\n",
    "    encoder_map = {\"mod1\": (model.encoder_body_mod1, model.encoder_head_mod1)}\n",
    "\n",
    "    # Looping over each modality (only 1 considered in the example)\n",
    "    for _, (body, head) in encoder_map.items():\n",
    "        subset = sampled_df\n",
    "\n",
    "        # Converting the selected feature columns to a torch tensor\n",
    "        x = torch.tensor(subset[feature_columns].values, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass through the encoder layers\n",
    "            h = body(x)\n",
    "            stats = head(h)\n",
    "            mu = stats[:, :model.latent_dim]\n",
    "\n",
    "        # Converting latent means to a dataframe\n",
    "        df_mu = pd.DataFrame(mu.cpu().numpy(), index=subset.index)\n",
    "        df_mu.columns = [f\"z{i+1}\" for i in range(model.latent_dim)]\n",
    "        latent_dfs.append(df_mu)\n",
    "\n",
    "    # Combine (if multiple modalities are used) and preserve ordering\n",
    "    latent_df = pd.concat(latent_dfs).sort_index()\n",
    "    return latent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144363ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:40.259528Z",
     "iopub.status.busy": "2025-09-05T06:54:40.259296Z",
     "iopub.status.idle": "2025-09-05T06:54:41.380788Z",
     "shell.execute_reply": "2025-09-05T06:54:41.379957Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering unwanted cell types before encoding the latent space\n",
    "# \"Unknown\" cell type act like extra noise added to the model\n",
    "X = X[X[\"cell_type\"] != \"unknown\"]\n",
    "\n",
    "# Extracting all features except for the sample_id and cell_type\n",
    "feature_cols = list(X.columns[:-2])\n",
    "\n",
    "# Computing the latent representation for the chosen modality\n",
    "latent_df_mod1 = encode_latent_space_by_mod_column_mod1(model, X, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317a5e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the same scaler used during training\n",
    "with open('./scaler_mod1.pkl', 'rb') as f:\n",
    "    scaler_mod1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f307de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:41.476178Z",
     "iopub.status.busy": "2025-09-05T06:54:41.475900Z",
     "iopub.status.idle": "2025-09-05T06:54:41.495215Z",
     "shell.execute_reply": "2025-09-05T06:54:41.494391Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Undo the MinMax scaling to return to the original range\n",
    "data_temp_mod1 = X.drop(columns=[\"sample_id\", \"cell_type\",]).values\n",
    "data_temp_mod1 = scaler_mod1.inverse_transform(data_temp_mod1)\n",
    "data_temp_mod1 = pd.DataFrame(data_temp_mod1, columns=X.drop(columns=[\"sample_id\", \"cell_type\"]).columns, index=X.index)\n",
    "data_temp_mod1[\"sample_id\"] = X[\"sample_id\"].values\n",
    "data_temp_mod1[\"cell_type\"] = X[\"cell_type\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83fbe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:41.587457Z",
     "iopub.status.busy": "2025-09-05T06:54:41.587181Z",
     "iopub.status.idle": "2025-09-05T06:54:41.605929Z",
     "shell.execute_reply": "2025-09-05T06:54:41.605296Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final merging of the original (unscaled) data with its latent representation\n",
    "merged_mod1 = pd.concat([data_temp_mod1.loc[latent_df_mod1.index], latent_df_mod1], axis=1)\n",
    "merged_mod1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3ff5a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806850f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:41.698323Z",
     "iopub.status.busy": "2025-09-05T06:54:41.698044Z",
     "iopub.status.idle": "2025-09-05T06:54:41.705180Z",
     "shell.execute_reply": "2025-09-05T06:54:41.704664Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latent_umap(latent_vecs, labels, sample_ids, color_by=\"cell_type\"):\n",
    "    reducer = umap.UMAP(random_state=3624)\n",
    "    Z_umap = reducer.fit_transform(latent_vecs)\n",
    "\n",
    "    cell_type_colors = {\n",
    "        'T1': '#D32F2F',\n",
    "        'T2': '#FF9800',\n",
    "        'MZ': '#2196F3',\n",
    "        'FM': '#9C27B0'\n",
    "    }\n",
    "\n",
    "    # Plot 1: UMAP colored by pre-set labels\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if color_by == \"cell_type\" and isinstance(labels[0], str):\n",
    "        unique_labels = np.unique(labels)\n",
    "        for lbl in unique_labels:\n",
    "            mask = np.array(labels) == lbl\n",
    "            color = cell_type_colors.get(lbl, \"#999999\")\n",
    "            plt.scatter(Z_umap[mask, 0], Z_umap[mask, 1], label=lbl, c=color, s=10, alpha=0.7, edgecolors='none')\n",
    "        plt.legend(title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.title(\"Latent Space UMAP\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: UMAPs faceted by Sample ID\n",
    "    unique_samples = np.unique(sample_ids)\n",
    "    ncols = 2\n",
    "    nrows = 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(6 * ncols, 6 * nrows), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, sample in zip(axes, unique_samples):\n",
    "        sample_mask = np.array(sample_ids) == sample\n",
    "        for lbl in np.unique(labels):\n",
    "            mask = (np.array(labels) == lbl) & sample_mask\n",
    "            color = cell_type_colors.get(lbl, \"#999999\")\n",
    "            ax.scatter(Z_umap[mask, 0], Z_umap[mask, 1], label=lbl, c=color, s=10, alpha=0.7, edgecolors='none')\n",
    "        ax.set_title(f\"Sample: {sample}\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    for j in range(len(unique_samples), len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    handles, labels_legend = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels_legend, title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.suptitle(\"Latent Space UMAP, faceted by Sample ID\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10f21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:56:29.259829Z",
     "iopub.status.busy": "2025-09-05T06:56:29.259693Z",
     "iopub.status.idle": "2025-09-05T06:56:29.265145Z",
     "shell.execute_reply": "2025-09-05T06:56:29.264648Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_latent_umap_continuous(latent_vecs, values, sample_ids, color_label=\"GFP-A Rag2\"):\n",
    "    reducer = umap.UMAP(random_state=3624)\n",
    "    Z_umap = reducer.fit_transform(latent_vecs)\n",
    "\n",
    "    # Plot 1: UMAP colored by a continuous label, here GFP\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(Z_umap[:, 0], Z_umap[:, 1], c=values, s=10, alpha=0.7, cmap=\"viridis\")\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(color_label)\n",
    "    plt.title(f\"Latent Space UMAP, by {color_label}\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: UMAPs faceted by Sample ID\n",
    "    unique_samples = np.unique(sample_ids)\n",
    "    ncols = 2\n",
    "    nrows = 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(6 * ncols, 6 * nrows), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    vmin, vmax = np.min(values), np.max(values)\n",
    "\n",
    "    for ax, sample in zip(axes, unique_samples):\n",
    "        sample_mask = np.array(sample_ids) == sample\n",
    "        scatter = ax.scatter(Z_umap[sample_mask, 0], Z_umap[sample_mask, 1],\n",
    "                             c=np.array(values)[sample_mask], s=10,\n",
    "                             alpha=0.7, cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"Sample: {sample}\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    for j in range(len(unique_samples), len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(scatter, cax=cbar_ax, label=color_label)\n",
    "\n",
    "    plt.suptitle(f\"Latent Space UMAP by {color_label}, faceted by Sample ID\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba20b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:54:41.797059Z",
     "iopub.status.busy": "2025-09-05T06:54:41.796785Z",
     "iopub.status.idle": "2025-09-05T06:56:29.112385Z",
     "shell.execute_reply": "2025-09-05T06:56:29.106098Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2D UMAP Representation of the Latent Space\n",
    "plot_latent_umap(\n",
    "    latent_vecs=latent_df_mod1.values,\n",
    "    labels=merged_mod1.loc[latent_df_mod1.index, \"cell_type\"].values,\n",
    "    sample_ids=merged_mod1.loc[latent_df_mod1.index, \"sample_id\"].values,\n",
    "    color_by=\"cell_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8f0f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T06:56:29.384955Z",
     "iopub.status.busy": "2025-09-05T06:56:29.384768Z",
     "iopub.status.idle": "2025-09-05T06:58:22.476079Z",
     "shell.execute_reply": "2025-09-05T06:58:22.475203Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_latent_umap_continuous(\n",
    "    latent_vecs=latent_df_mod1.values,\n",
    "    values=merged_mod1[\"GFP-A Rag2\"].values,\n",
    "    sample_ids=merged_mod1[\"sample_id\"].values,\n",
    "    color_label=\"GFP-A Rag2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f352c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3D Rendering: Latent Space colored by cell type\n",
    "cell_type_colors = {\n",
    "        'T1': '#D32F2F',\n",
    "        'T2': '#FF9800',\n",
    "        'MZ': '#2196F3',\n",
    "        'FM': '#9C27B0'\n",
    "}\n",
    "\n",
    "fig = px.scatter_3d(merged_mod1,\n",
    "                    x=merged_mod1['z1'],\n",
    "                    y=merged_mod1['z2'],\n",
    "                    z=merged_mod1['z3'],\n",
    "                    color='cell_type',\n",
    "                    title=f'3D Representation of Latent Space, sample of {len(X)} cells',\n",
    "                    color_discrete_map=cell_type_colors)\n",
    "\n",
    "fig.update_traces(marker=dict(size=2, opacity=1))\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        itemsizing='constant',\n",
    "        itemwidth=30,\n",
    "        itemclick='toggleothers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a899e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3D Rendering: Latent Space colored by GFP-A\n",
    "fig = px.scatter_3d(merged_mod1,\n",
    "                    x=merged_mod1['z1'],\n",
    "                    y=merged_mod1['z2'],\n",
    "                    z=merged_mod1['z3'],\n",
    "                    color='GFP-A Rag2',\n",
    "                    title=f'3D Representation of Latent Space, sample of {len(X)} cells',\n",
    "                    color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_traces(marker=dict(size=2, opacity=1))\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        itemsizing='constant',\n",
    "        itemwidth=30,\n",
    "        itemclick='toggleothers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show(renderer='browser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9156.844436,
   "end_time": "2025-10-23T19:35:43.339564",
   "environment_variables": {},
   "exception": true,
   "input_path": "cell_wise_mm_vae_28_mod1.ipynb",
   "output_path": "cell_wise_mm_vae_28_mod1.ipynb",
   "parameters": {},
   "start_time": "2025-10-23T17:03:06.495128",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
